{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       1\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n",
      "(404287, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363858, 6) (40429, 6)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.9 * len(df))\n",
    "df_train = df[:split]\n",
    "df_test_val = df[split:]\n",
    "del(df)\n",
    "print(df_train.shape,df_test_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20215, 6) (20214, 6)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.5 * len(df_test_val))\n",
    "df_val = df_test_val[:split]\n",
    "df_test = df_test_val[split:]\n",
    "del(df_test_val)\n",
    "print(df_test.shape,df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(df):\n",
    "    '''\n",
    "    Function to process the dataset to extract the Question Pairs \n",
    "    and the Labels.\n",
    "    '''\n",
    "    ques1 = df.question1.values\n",
    "    ques2 = df.question2.values\n",
    "    labels = df.is_duplicate.values\n",
    "    return ques1,ques2,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1 : What is the step by step guide to invest in share market in india?\n",
      "Question2 : What is the step by step guide to invest in share market?\n",
      "Is_Duplicate : 0\n",
      "Question1 : What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "Question2 : What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
      "Is_Duplicate : 0\n"
     ]
    }
   ],
   "source": [
    "Q1_train,Q2_train,Y_train = process_dataset(df_train)\n",
    "for i in range(2):\n",
    "    print('Question1 :',Q1_train[i])\n",
    "    print('Question2 :',Q2_train[i])\n",
    "    print('Is_Duplicate :',Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_test,Q2_test,Y_test = process_dataset(df_test)\n",
    "Q1_val,Q2_val,Y_val = process_dataset(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(np.concatenate([Q1_train,Q2_train,Q1_val,Q2_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index\n",
    "train_Q1 = tokenizer.texts_to_sequences(Q1_train)\n",
    "train_Q2 = tokenizer.texts_to_sequences(Q2_train)\n",
    "val_Q1 = tokenizer.texts_to_sequences(Q1_val)\n",
    "val_Q2 = tokenizer.texts_to_sequences(Q2_val)\n",
    "test_Q1 = tokenizer.texts_to_sequences(Q1_test)\n",
    "test_Q2 = tokenizer.texts_to_sequences(Q2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363858, 128) (363858, 128) (20214, 128) (20214, 128) (20215, 128) (20215, 128)\n"
     ]
    }
   ],
   "source": [
    "train_Q1 = pad_sequences(train_Q1,maxlen=128,padding='post',truncating='post')\n",
    "train_Q2 = pad_sequences(train_Q2,maxlen=128,padding='post',truncating='post')\n",
    "val_Q1 = pad_sequences(val_Q1,maxlen=128,padding='post',truncating='post')\n",
    "val_Q2 = pad_sequences(val_Q2,maxlen=128,padding='post',truncating='post')\n",
    "test_Q1 = pad_sequences(test_Q1,maxlen=128,padding='post',truncating='post')\n",
    "test_Q2 = pad_sequences(test_Q2,maxlen=128,padding='post',truncating='post')\n",
    "print(train_Q1.shape,train_Q2.shape,val_Q1.shape,val_Q2.shape,test_Q1.shape,test_Q2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_base_network(num_words = len(vocab)+1,embed_dim = 64):\n",
    "    input = tf.keras.layers.Input(shape=(128,), name=\"base_input\")\n",
    "    x   = tf.keras.layers.Embedding(input_dim = num_words,output_dim=embed_dim)(input)\n",
    "    x   = tf.keras.layers.LSTM(128,return_sequences=True)(x)\n",
    "    #x   = tf.keras.layers.Dropout(0.1)(x)\n",
    "    #x   = tf.keras.layers.LSTM(128,return_sequences=True)(x)\n",
    "    #x   = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x   = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    #x   = tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "    return tf.keras.models.Model(inputs=input, outputs=x)\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = initialize_base_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "base_input (InputLayer)      [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 128, 64)           5973888   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128, 128)          98816     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 6,072,704\n",
      "Trainable params: 6,072,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = tf.keras.layers.Input(shape=(128,), name=\"left_input\")\n",
    "vect_output_a = base_network(input_a)\n",
    "\n",
    "# create the right input and point to the base network\n",
    "input_b = tf.keras.layers.Input(shape=(128,), name=\"right_input\")\n",
    "vect_output_b = base_network(input_b)\n",
    "\n",
    "# measure the similarity of the two vector outputs\n",
    "output = tf.keras.layers.Lambda(euclidean_distance, name=\"output_layer\", output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.models.Model([input_a, input_b], output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_input (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_input (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 128)          6072704     left_input[0][0]                 \n",
      "                                                                 right_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Lambda)           (None, 1)            0           model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "==================================================================================================\n",
      "Total params: 6,072,704\n",
      "Trainable params: 6,072,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        '''Contrastive loss from Hadsell-et-al.'06\n",
    "        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "        '''\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(Y_train,dtype=np.float32)\n",
    "Y_val = np.array(Y_val,dtype=np.float32)\n",
    "Y_test = np.array(Y_test,dtype=np.float32)\n",
    "Y_train.dtype,Y_val.dtype,Y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=contrastive_loss_with_margin(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "178/178 [==============================] - 74s 417ms/step - loss: 0.4338 - val_loss: 1.1534\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 74s 417ms/step - loss: 0.3854 - val_loss: 1.1576\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 74s 417ms/step - loss: 0.3556 - val_loss: 1.1596\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 74s 417ms/step - loss: 0.3329 - val_loss: 1.1638\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 74s 416ms/step - loss: 0.3144 - val_loss: 1.1697\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 74s 417ms/step - loss: 0.2987 - val_loss: 1.1759\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 74s 418ms/step - loss: 0.2850 - val_loss: 1.1810\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 73s 412ms/step - loss: 0.2730 - val_loss: 1.1874\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 72s 404ms/step - loss: 0.2620 - val_loss: 1.1959\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 72s 403ms/step - loss: 0.2518 - val_loss: 1.1986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a93596d490>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[train_Q1,train_Q2],y=Y_train,batch_size=2048,epochs=10,validation_data=([val_Q1,val_Q2],Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,Q1,Q2,threshold=0.7):\n",
    "  \n",
    "    prediction = []\n",
    "    \n",
    "    v1 = model.predict(Q1)\n",
    "    v2 = model.predict(Q2)\n",
    "    \n",
    "    for i in range(len(Q1)):\n",
    "        \n",
    "        dot_product = np.dot(v1[i],v2[i].T)\n",
    "        cos_sim = dot_product/(np.linalg.norm(v1[i]) * np.linalg.norm(v2[i]))\n",
    "        if cos_sim > threshold:\n",
    "            score = 1\n",
    "          \n",
    "        else:\n",
    "            score = 0\n",
    "        \n",
    "        prediction.append(score)\n",
    "    return np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384075</th>\n",
       "      <td>384075</td>\n",
       "      <td>408489</td>\n",
       "      <td>304764</td>\n",
       "      <td>What is the biggest lie you ever told to yours...</td>\n",
       "      <td>What is the biggest lie you have told yourself?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384076</th>\n",
       "      <td>384076</td>\n",
       "      <td>65043</td>\n",
       "      <td>277644</td>\n",
       "      <td>What are some tips on making it through the jo...</td>\n",
       "      <td>What are some tips on making it through the jo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384077</th>\n",
       "      <td>384077</td>\n",
       "      <td>283606</td>\n",
       "      <td>276977</td>\n",
       "      <td>What are the questions asked in SSB interviews?</td>\n",
       "      <td>What are some questions asked in SSB interview?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384078</th>\n",
       "      <td>384078</td>\n",
       "      <td>516074</td>\n",
       "      <td>516075</td>\n",
       "      <td>My boyfriend bought two mice from a pet store ...</td>\n",
       "      <td>What is acoustic emanation?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384079</th>\n",
       "      <td>384079</td>\n",
       "      <td>516076</td>\n",
       "      <td>516077</td>\n",
       "      <td>Is there any chance of Eminem coming to India ...</td>\n",
       "      <td>What are the chances of Eminem coming and perf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "384075  384075  408489  304764   \n",
       "384076  384076   65043  277644   \n",
       "384077  384077  283606  276977   \n",
       "384078  384078  516074  516075   \n",
       "384079  384079  516076  516077   \n",
       "\n",
       "                                                question1  \\\n",
       "384075  What is the biggest lie you ever told to yours...   \n",
       "384076  What are some tips on making it through the jo...   \n",
       "384077    What are the questions asked in SSB interviews?   \n",
       "384078  My boyfriend bought two mice from a pet store ...   \n",
       "384079  Is there any chance of Eminem coming to India ...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "384075    What is the biggest lie you have told yourself?             1  \n",
       "384076  What are some tips on making it through the jo...             0  \n",
       "384077    What are some questions asked in SSB interview?             1  \n",
       "384078                        What is acoustic emanation?             0  \n",
       "384079  What are the chances of Eminem coming and perf...             1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = df_test.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = []\n",
    "false_neg = []\n",
    "accuracy =[]\n",
    "values = [0.8,0.825,0.85,0.875,0.9,0.925,0.94,0.95,0.96,0.97]\n",
    "for thresh in values:\n",
    "    Y_hat = predict(base_network,test_Q1,test_Q2,thresh)\n",
    "    acc = np.sum(Y_hat == Y_test)/len(Y_test)\n",
    "    accuracy.append(acc)\n",
    "    fn = 0 \n",
    "    fp = 0\n",
    "    for x,y in zip(Y_hat,Y_test):\n",
    "        \n",
    "        if x!=y:\n",
    "        \n",
    "            if y == 1:\n",
    "                fn += 1\n",
    "            \n",
    "            else:\n",
    "                fp += 1\n",
    "            \n",
    "    false_pos.append(fp)\n",
    "    false_neg.append(fn)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyse = pd.DataFrame({'Threshold_Value':values,\n",
    "                           'False_Positives':false_pos,\n",
    "                           'False_Negatives':false_neg,\n",
    "                           'Wrong Predictions': [x + y for x,y in zip(false_neg,false_pos)],\n",
    "                           'Accuracy':accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold_Value</th>\n",
       "      <th>False_Positives</th>\n",
       "      <th>False_Negatives</th>\n",
       "      <th>Wrong Predictions</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>2755</td>\n",
       "      <td>1069</td>\n",
       "      <td>3824</td>\n",
       "      <td>0.810834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.825</td>\n",
       "      <td>2406</td>\n",
       "      <td>1186</td>\n",
       "      <td>3592</td>\n",
       "      <td>0.822310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850</td>\n",
       "      <td>2070</td>\n",
       "      <td>1317</td>\n",
       "      <td>3387</td>\n",
       "      <td>0.832451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.875</td>\n",
       "      <td>1761</td>\n",
       "      <td>1455</td>\n",
       "      <td>3216</td>\n",
       "      <td>0.840910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900</td>\n",
       "      <td>1443</td>\n",
       "      <td>1661</td>\n",
       "      <td>3104</td>\n",
       "      <td>0.846451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>1168</td>\n",
       "      <td>1902</td>\n",
       "      <td>3070</td>\n",
       "      <td>0.848133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.940</td>\n",
       "      <td>1005</td>\n",
       "      <td>2084</td>\n",
       "      <td>3089</td>\n",
       "      <td>0.847193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.950</td>\n",
       "      <td>894</td>\n",
       "      <td>2220</td>\n",
       "      <td>3114</td>\n",
       "      <td>0.845956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.960</td>\n",
       "      <td>780</td>\n",
       "      <td>2404</td>\n",
       "      <td>3184</td>\n",
       "      <td>0.842493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.970</td>\n",
       "      <td>651</td>\n",
       "      <td>2609</td>\n",
       "      <td>3260</td>\n",
       "      <td>0.838734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold_Value  False_Positives  False_Negatives  Wrong Predictions  \\\n",
       "0            0.800             2755             1069               3824   \n",
       "1            0.825             2406             1186               3592   \n",
       "2            0.850             2070             1317               3387   \n",
       "3            0.875             1761             1455               3216   \n",
       "4            0.900             1443             1661               3104   \n",
       "5            0.925             1168             1902               3070   \n",
       "6            0.940             1005             2084               3089   \n",
       "7            0.950              894             2220               3114   \n",
       "8            0.960              780             2404               3184   \n",
       "9            0.970              651             2609               3260   \n",
       "\n",
       "   Accuracy  \n",
       "0  0.810834  \n",
       "1  0.822310  \n",
       "2  0.832451  \n",
       "3  0.840910  \n",
       "4  0.846451  \n",
       "5  0.848133  \n",
       "6  0.847193  \n",
       "7  0.845956  \n",
       "8  0.842493  \n",
       "9  0.838734  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From The Above table we can see that the best Threshold Value for the Model will be in the range [0.92,0.94)\n",
    "### The model Has an Accuracy of approximately 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
